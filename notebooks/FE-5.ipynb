{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "#%autosave 20\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "os.environ['KERAS_BACKEND']='theano'\n",
    "import keras\n",
    "import sys\n",
    "sys.path.append('/home/peter')\n",
    "sys.path.append('/home/peter/code/projects/MultiNEAT')\n",
    "sys.path.append('/home/ubuntu')\n",
    "#from universal import *\n",
    "sys.path.append('/home/peter/code/projects')\n",
    "sys.path.append('c:/users/spook/dropbox/code/projects')\n",
    "sys.path.append('/home/peter/code/work/automl')\n",
    "sys.path.append('/home/peter/code/projects/deepneat')\n",
    "sys.path.append('/home/ubuntu')\n",
    "sys.path.append('/home/ubuntu/new/automl')\n",
    "from aidevutil import *\n",
    "from keras.utils.vis_utils import plot_model\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "#from deepneat import *\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "#from project_common import *\n",
    "#import project_common\n",
    "from sklearn.feature_selection import *\n",
    "from sklearn.feature_extraction import *\n",
    "from sklearn.neighbors import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "rnd.seed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from dask import compute, delayed, persist\n",
    "from dask.distributed import Client, wait\n",
    "from dask.distributed import as_completed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.decomposition import DictionaryLearning, FactorAnalysis, FastICA, LatentDirichletAllocation, NMF, TruncatedSVD\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\n",
    "from sklearn.cross_decomposition import CCA, PLSCanonical, PLSRegression, PLSSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import multiprocessing as mpc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "(x_train, y_train), (x_test, y_test) = get_mnist(size=(5,5), nrows=2000, nrows_test=2000)\n",
    "dx = x_train.reshape(x_train.shape[0], -1) / 255.0\n",
    "dy = y_train.reshape(-1, 1)\n",
    "\n",
    "dx_test = x_test.reshape(x_test.shape[0], -1) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     3,
     6
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# def revsigm(data):\n",
    "#     return 1.-(1./(1.+np.exp(-data)))\n",
    "\n",
    "# def Outputs(data):\n",
    "#     return np.round(revsigm(data))\n",
    "    \n",
    "# def MungeData(data):\n",
    "#     # Sex\n",
    "#     data.drop(['Ticket', 'Name'], inplace=True, axis=1)\n",
    "#     data.Sex.fillna('0', inplace=True)\n",
    "#     data.loc[data.Sex != 'male', 'Sex'] = 0\n",
    "#     data.loc[data.Sex == 'male', 'Sex'] = 1\n",
    "#     # Cabin\n",
    "#     cabin_const = 1\n",
    "#     data.Cabin.fillna(str(cabin_const), inplace=True)\n",
    "#     data.loc[data.Cabin.str[0] == 'A', 'Cabin'] = cabin_const\n",
    "#     data.loc[data.Cabin.str[0] == 'B', 'Cabin'] = cabin_const\n",
    "#     data.loc[data.Cabin.str[0] == 'C', 'Cabin'] = cabin_const\n",
    "#     data.loc[data.Cabin.str[0] == 'D', 'Cabin'] = cabin_const\n",
    "#     data.loc[data.Cabin.str[0] == 'E', 'Cabin'] = cabin_const\n",
    "#     data.loc[data.Cabin.str[0] == 'F', 'Cabin'] = cabin_const\n",
    "#     data.loc[data.Cabin.str[0] == 'G', 'Cabin'] = cabin_const\n",
    "#     data.loc[data.Cabin.str[0] == 'T', 'Cabin'] = cabin_const\n",
    "#     # Embarked\n",
    "#     data.loc[data.Embarked == 'C', 'Embarked'] = 1\n",
    "#     data.loc[data.Embarked == 'Q', 'Embarked'] = 2\n",
    "#     data.loc[data.Embarked == 'S', 'Embarked'] = 3\n",
    "#     data.Embarked.fillna(0, inplace=True)\n",
    "#     data.fillna(-1, inplace=True)\n",
    "#     return data.astype(float)\n",
    "\n",
    "# if socket.gethostname() in ['desktop','laptop']:\n",
    "#     train = pd.read_csv(\"../../work/automl/titanic/train.csv\", dtype={\"Age\": np.float64}, )\n",
    "#     test = pd.read_csv(\"../../work/automl/titanic/test.csv\", dtype={\"Age\": np.float64}, )\n",
    "# else:\n",
    "#     train = pd.read_csv(\"/home/ubuntu/new/automl/titanic/train.csv\", dtype={\"Age\": np.float64}, )\n",
    "#     test = pd.read_csv(\"/home/ubuntu/new/automl/titanic/test.csv\", dtype={\"Age\": np.float64}, )\n",
    "    \n",
    "# mdt = MungeData(train)\n",
    "\n",
    "# dy = mdt['Survived'].values\n",
    "# dx = mdt.drop(['Survived'], axis=1).values[:,1:]\n",
    "# dx_test_df = MungeData(test)\n",
    "# dx_test = dx_test_df.values[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the arrays\n",
    "a = [float(x) for x in open('tit_x.txt').read().split()]\n",
    "cols = int(a[0])\n",
    "dx = array(a[1:]).reshape(-1, cols)\n",
    "dx.shape\n",
    "\n",
    "a = [float(x) for x in open('tit_x_test.txt').read().split()]\n",
    "cols = int(a[0])\n",
    "dx_test = array(a[1:]).reshape(-1, cols)\n",
    "dx_test.shape\n",
    "\n",
    "dy = array([float(x) for x in open('tit_y.txt').read().split()])\n",
    "dy.shape\n",
    "\n",
    "dy_test = array([float(x) for x in open('tit_y_test.txt').read().split()])\n",
    "dy_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {
    "code_folding": [
     0
    ],
    "run_control": {
     "marked": false
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dx.shape, dy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rf = np.arange(dx.shape[1])\n",
    "rf = rnd.sample(rf.tolist(), 16)\n",
    "dx = dx[:, rf]\n",
    "dx_test = dx_test[:, rf]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dx.shape, dy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "clf = LogisticRegression()\n",
    "clf.fit(dx, dy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dxx = hstack([dx, clf.predict(dx).reshape(-1,1)])\n",
    "dxx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "### Base trait class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class BaseObject: \n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def mate(self, other):\n",
    "        baby = BaseObject()\n",
    "        return baby\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = BaseObject()\n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        return rnd.uniform(0,1)\n",
    "\n",
    "    def fit(self, x, y):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, x, y):\n",
    "        return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class_distance = 3.0\n",
    "replace_class_prob = 0.02\n",
    "mutation_prob = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derived Classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class genePCA(BaseObject): \n",
    "    def __init__(self):\n",
    "        self.ndim = rnd.randint(1, dx.shape[1]-1)\n",
    "        self.pca = PCA(n_components=self.ndim)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"PCA(%d)\" % self.ndim\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, genePCA):\n",
    "            baby = genePCA()\n",
    "            baby.ndim = (self.ndim + other.ndim)//2\n",
    "            baby.pca = PCA(n_components=baby.ndim)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = genePCA()\n",
    "        baby.ndim += rnd.randint(-3, 3)\n",
    "        baby.ndim = np.clip(baby.ndim, 1, dx.shape[1]-1)\n",
    "        baby.pca = PCA(n_components=baby.ndim)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, genePCA):\n",
    "            return float(np.abs(self.ndim - other.ndim))\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        self.pca.fit(x, y=y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        xt = self.pca.transform(x)\n",
    "        return np.array(xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneLDA(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['solver'] = rnd.choice(['svd','lsqr','eigen'])\n",
    "        ps['shrinkage'] = rnd.choice([None, 'auto', 0.0, 0.1, 0.5, 0.75, 1.0])\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = LinearDiscriminantAnalysis(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"LDA()\"\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneLDA):\n",
    "            baby = geneLDA()\n",
    "            ps = self.ps\n",
    "            \n",
    "            for k, v in ps.items():\n",
    "                if rnd.uniform(0,1)<0.5: ps[k] = rnd.choice([self.ps[k], other.ps[k]])\n",
    "            \n",
    "            baby.clf = LinearDiscriminantAnalysis(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneLDA()\n",
    "        ps = self.ps\n",
    "        \n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['solver'] = rnd.choice(['svd','lsqr','eigen'])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['shrinkage'] = rnd.choice([None, 'auto', 0.0, 0.1, 0.5, 0.75, 1.0])\n",
    "        \n",
    "        baby.clf = LinearDiscriminantAnalysis(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneLDA):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### QDA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class geneQDA(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        #ps['solver'] = rnd.choice(['svd','lsqr','eigen'])\n",
    "        #ps['shrinkage'] = rnd.choice([None, 'auto', 0.0, 0.1, 0.5, 0.75, 1.0])\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = QuadraticDiscriminantAnalysis(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"QDA()\"\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneQDA):\n",
    "            baby = geneQDA()\n",
    "            ps = self.ps\n",
    "            \n",
    "            for k, v in ps.items():\n",
    "                if rnd.uniform(0,1)<0.5: ps[k] = rnd.choice([self.ps[k], other.ps[k]])\n",
    "            \n",
    "            baby.clf = QuadraticDiscriminantAnalysis(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneQDA()\n",
    "        ps = self.ps\n",
    "        \n",
    "        #if rnd.uniform(0,1)<mutation_prob: ps['solver'] = rnd.choice(['svd','lsqr','eigen'])\n",
    "        #if rnd.uniform(0,1)<mutation_prob: ps['shrinkage'] = rnd.choice([None, 'auto', 0.0, 0.1, 0.5, 0.75, 1.0])\n",
    "        \n",
    "        baby.clf = QuadraticDiscriminantAnalysis(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneQDA):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectKBest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneSelectKBest(BaseObject): \n",
    "    def __init__(self):\n",
    "        self.k = rnd.randint(1, dx.shape[1]-1)\n",
    "        self.clf = SelectKBest(score_func = f_classif, k=self.k)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"SelectKBest(%d)\" % self.k\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneSelectKBest):\n",
    "            baby = geneSelectKBest()\n",
    "            baby.k = (self.k + other.k)//2\n",
    "            baby.clf = SelectKBest(score_func = f_classif, k=baby.k)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneSelectKBest()\n",
    "        baby.k += rnd.randint(-3, 3)\n",
    "        baby.k = np.clip(baby.k, 1, dx.shape[1]-1)\n",
    "        baby.clf = SelectKBest(score_func = f_classif, k=baby.k)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneSelectKBest):\n",
    "            return float(np.abs(self.k - other.k))\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y=None):\n",
    "        self.clf.fit(x, y=y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        xt = self.clf.transform(x)\n",
    "        return np.array(xt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectPercentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneSelectPercentile(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['score_func'] = f_classif \n",
    "        ps['percentile'] = rnd.randint(0,100)\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = SelectPercentile(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"SelectPercentile(%d)\" % self.ps['percentile']\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneSelectPercentile):\n",
    "            baby = geneSelectPercentile()\n",
    "            ps = self.ps\n",
    "            \n",
    "            for k, v in ps.items():\n",
    "                if rnd.uniform(0,1)<0.5: ps[k] = rnd.choice([self.ps[k], other.ps[k]])\n",
    "            \n",
    "            baby.clf = SelectPercentile(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneSelectPercentile()\n",
    "        ps = self.ps\n",
    "        \n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['score_func'] = f_classif \n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['percentile'] = rnd.randint(0,100)\n",
    "        \n",
    "        baby.clf = SelectPercentile(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneSelectPercentile):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneSelectFpr(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['score_func'] = f_classif \n",
    "        ps['alpha'] = rnd.uniform(0.00001,0.1)\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = SelectFpr(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"SelectFpr(%3.3f)\" % self.ps['alpha']\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneSelectFpr):\n",
    "            baby = geneSelectFpr()\n",
    "            ps = self.ps\n",
    "            \n",
    "            for k, v in ps.items():\n",
    "                if rnd.uniform(0,1)<0.5: ps[k] = rnd.choice([self.ps[k], other.ps[k]])\n",
    "            \n",
    "            baby.clf = SelectFpr(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneSelectFpr()\n",
    "        ps = self.ps\n",
    "        \n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['score_func'] = f_classif \n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['alpha'] = rnd.uniform(0.00001,0.1)\n",
    "        \n",
    "        baby.clf = SelectFpr(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneSelectFpr):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class geneSelectFdr(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['score_func'] = f_classif \n",
    "        ps['alpha'] = rnd.uniform(0.00001,0.1)\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = SelectFdr(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"SelectFdr(%3.3f)\" % self.ps['alpha']\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneSelectFdr):\n",
    "            baby = geneSelectFdr()\n",
    "            ps = self.ps\n",
    "            \n",
    "            for k, v in ps.items():\n",
    "                if rnd.uniform(0,1)<0.5: ps[k] = rnd.choice([self.ps[k], other.ps[k]])\n",
    "            \n",
    "            baby.clf = SelectFdr(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneSelectFdr()\n",
    "        ps = self.ps\n",
    "        \n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['score_func'] = f_classif \n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['alpha'] = rnd.uniform(0.00001,0.1)\n",
    "        \n",
    "        baby.clf = SelectFdr(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneSelectFdr):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectFwe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class geneSelectFwe(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['score_func'] = f_classif \n",
    "        ps['alpha'] = rnd.uniform(0.00001,0.1)\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = SelectFwe(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"SelectFwe(%3.3f)\" % self.ps['alpha']\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneSelectFwe):\n",
    "            baby = geneSelectFwe()\n",
    "            ps = self.ps\n",
    "            \n",
    "            for k, v in ps.items():\n",
    "                if rnd.uniform(0,1)<0.5: ps[k] = rnd.choice([self.ps[k], other.ps[k]])\n",
    "            \n",
    "            baby.clf = SelectFwe(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneSelectFwe()\n",
    "        ps = self.ps\n",
    "        \n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['score_func'] = f_classif \n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['alpha'] = rnd.uniform(0.00001,0.1)\n",
    "        \n",
    "        baby.clf = SelectFwe(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneSelectFwe):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VarianceThreshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneVarianceThreshold(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['threshold'] = rnd.choice([0.0, 0.01, 0.05 ,0.1])\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = VarianceThreshold(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"VarianceThreshold(%3.3f)\" % self.ps['threshold']\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneVarianceThreshold):\n",
    "            baby = geneVarianceThreshold()\n",
    "            ps = self.ps\n",
    "            \n",
    "            for k, v in ps.items():\n",
    "                if rnd.uniform(0,1)<0.5: ps[k] = rnd.choice([self.ps[k], other.ps[k]])\n",
    "            \n",
    "            baby.clf = VarianceThreshold(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneVarianceThreshold()\n",
    "        ps = self.ps\n",
    "        \n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['threshold'] = rnd.choice([0.0, 0.01, 0.05 ,0.1])\n",
    "        \n",
    "        baby.clf = VarianceThreshold(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneVarianceThreshold):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SelectSlice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class geneSelectSlice(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        \n",
    "        ps['a'] = 0\n",
    "        ps['b'] = 0\n",
    "        while ps['b'] == 0:\n",
    "            ps['a'] = rnd.randint(0, dx.shape[1]-1) \n",
    "            ps['b'] = rnd.randint(0, dx.shape[1]-ps['a']+1)\n",
    "        \n",
    "        self.ps = ps\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"SelectSlice(%d,%d)\" % (self.ps['a'], self.ps['a']+self.ps['b'])\n",
    "    \n",
    "    def mate(self, other):\n",
    "        return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneSelectSlice()\n",
    "        ps = self.ps\n",
    "        \n",
    "        if rnd.uniform(0,1)<mutation_prob:\n",
    "            ps['a'] = 0\n",
    "            ps['b'] = 0\n",
    "            while ps['b'] == 0:\n",
    "                ps['a'] = rnd.randint(0, dx.shape[1]-1) \n",
    "                ps['b'] = rnd.randint(0, dx.shape[1]-ps['a']+1)\n",
    "\n",
    "        baby.ps = ps\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneSelectSlice):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        pass\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return x[..., self.ps['a'] : self.ps['a'] + self.ps['b']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneNormalize(BaseObject): \n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Normalize()\"\n",
    "    \n",
    "    def mate(self, other):\n",
    "        return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneNormalize()\n",
    "               \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneNormalize):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.tx = np.mean(x, axis=0)\n",
    "        self.ts = np.max(x, axis=0) - np.min(x, axis=0)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return (x - self.tx)/self.ts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DictionaryLearning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneDictionaryLearning(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        #ps['score_func'] = f_classif \n",
    "        #ps['alpha'] = rnd.uniform(0.00001,0.1)\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = DictionaryLearning(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"DictionaryLearning()\"\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneDictionaryLearning):\n",
    "            baby = geneDictionaryLearning()\n",
    "            ps = self.ps\n",
    "            \n",
    "            for k, v in ps.items():\n",
    "                if rnd.uniform(0,1)<0.5: ps[k] = rnd.choice([self.ps[k], other.ps[k]])\n",
    "            \n",
    "            baby.clf = DictionaryLearning(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneDictionaryLearning()\n",
    "        ps = self.ps\n",
    "        \n",
    "        #if rnd.uniform(0,1)<mutation_prob: ps['score_func'] = f_classif \n",
    "        #if rnd.uniform(0,1)<mutation_prob: ps['alpha'] = rnd.uniform(0.00001,0.1)\n",
    "        \n",
    "        baby.clf = DictionaryLearning(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneDictionaryLearning):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FactorAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FastICA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneFastICA(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['n_components'] = rnd.randint(1, dx.shape[1]) \n",
    "        ps['algorithm'] = rnd.choice(['parallel', 'deflation'])\n",
    "        ps['whiten'] = rnd.choice([True, False])\n",
    "        ps['max_iter'] = rnd.choice([10, 25, 40, 50, 100, 150, 200, 300])\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = FastICA(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"FastICA()\"\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneFastICA):\n",
    "            baby = geneFastICA()\n",
    "            ps = self.ps\n",
    "            \n",
    "            for k, v in ps.items():\n",
    "                if rnd.uniform(0,1)<0.5: ps[k] = rnd.choice([self.ps[k], other.ps[k]])\n",
    "            \n",
    "            baby.clf = FastICA(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneFastICA()\n",
    "        ps = self.ps\n",
    "        \n",
    "        if rnd.uniform(0,1)<mutation_prob:ps['n_components'] = rnd.randint(1, dx.shape[1]) \n",
    "        if rnd.uniform(0,1)<mutation_prob:ps['algorithm'] = rnd.choice(['parallel', 'deflation'])\n",
    "        if rnd.uniform(0,1)<mutation_prob:ps['whiten'] = rnd.choice([True, False])\n",
    "        if rnd.uniform(0,1)<mutation_prob:ps['max_iter'] = rnd.choice([10, 25, 40, 50, 100, 150, 200, 300])\n",
    "        \n",
    "        baby.clf = FastICA(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneFastICA):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.transform(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLSCanonical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLSRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PLSSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneLinear(BaseObject): \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return \"Linear\"\n",
    "    \n",
    "    def mate(self, other):\n",
    "        return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return self\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneLinear):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        pass\n",
    "    \n",
    "    def transform(self, x, y):\n",
    "        return np.array(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneLogisticRegression(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['penalty'] = rnd.choice(['l1','l2'\n",
    "                                   ])\n",
    "        ps['dual'] = rnd.choice([False])\n",
    "        ps['fit_intercept'] = rnd.choice([True, False])\n",
    "        ps['solver'] = rnd.choice(['liblinear'#, 'sag', 'saga'\n",
    "                                  ])\n",
    "        ps['C'] = rnd.choice([0.5, 0.75, 0.95, 1.0])\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = LogisticRegression(**ps, max_iter=10000)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"LGRG(%s,%s,%s)\" % (self.ps['penalty'], self.ps['dual'], self.ps['fit_intercept'])\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneLogisticRegression):\n",
    "            baby = geneLogisticRegression()\n",
    "            ps = self.ps\n",
    "            if rnd.uniform(0,1)<0.5: ps['penalty'] = rnd.choice([self.ps['penalty'], other.ps['penalty']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['dual'] = rnd.choice([self.ps['dual'], other.ps['dual']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['fit_intercept'] = rnd.choice([self.ps['fit_intercept'], other.ps['fit_intercept']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['solver'] = rnd.choice([self.ps['solver'], other.ps['solver']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['C'] = rnd.choice([self.ps['C'], other.ps['C']])\n",
    "            baby.clf = LogisticRegression(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneLogisticRegression()\n",
    "        ps = self.ps\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['penalty'] = rnd.choice(['l1','l2'\n",
    "                                                                      ])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['dual'] = rnd.choice([False])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['fit_intercept'] = rnd.choice([True, False])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['solver'] = rnd.choice(['liblinear',# 'sag', 'saga'\n",
    "                                                                     ])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['C'] = rnd.choice([0.5, 0.75, 0.95, 1.0])\n",
    "        baby.clf = LogisticRegression(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneLogisticRegression):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneDecisionTreeClassifier(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['criterion'] = rnd.choice(['gini','entropy'])\n",
    "        ps['splitter'] = rnd.choice(['best', 'random'])\n",
    "        ps['max_depth'] = rnd.choice([None, 1, 3, 5])\n",
    "        ps['max_features'] = rnd.choice([None, 0.25, 0.5, 0.8])\n",
    "        ps['min_samples_split'] = rnd.choice([2,3])\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = DecisionTreeClassifier(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"DTC(%s,%s,%s,%s,%s)\" % (self.ps['criterion'], \n",
    "                                  self.ps['splitter'], \n",
    "                                  self.ps['max_depth'],\n",
    "                                  self.ps['max_features'],\n",
    "                                  self.ps['min_samples_split'])\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneDecisionTreeClassifier):\n",
    "            baby = geneDecisionTreeClassifier()\n",
    "            ps = self.ps\n",
    "            if rnd.uniform(0,1)<0.5: ps['criterion'] = rnd.choice([self.ps['criterion'], other.ps['criterion']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['splitter'] = rnd.choice([self.ps['splitter'], other.ps['splitter']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['max_depth'] = rnd.choice([self.ps['max_depth'], other.ps['max_depth']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['max_features'] = rnd.choice([self.ps['max_features'], other.ps['max_features']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['min_samples_split'] = rnd.choice([self.ps['min_samples_split'], \n",
    "                                                                           other.ps['min_samples_split']])\n",
    "            baby.clf = DecisionTreeClassifier(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneDecisionTreeClassifier()\n",
    "        \n",
    "        ps = self.ps\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['criterion'] = rnd.choice(['gini','entropy'])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['splitter'] = rnd.choice(['best', 'random'])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['max_depth'] = rnd.choice([None, 1, 3, 5])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['max_features'] = rnd.choice([None, 0.25, 0.5, 0.8])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['min_samples_split'] = rnd.choice([2,3])\n",
    "        baby.clf = DecisionTreeClassifier(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneDecisionTreeClassifier):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class geneSVC(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['C'] = rnd.choice([0.1, 1.0, 10.0])\n",
    "        ps['kernel'] = rnd.choice(['linear', 'rbf'])\n",
    "        ps['probability'] = rnd.choice([True])\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = SVC(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"SVC(%s,%s,%s)\" % (self.ps['C'], \n",
    "                                  self.ps['kernel'],\n",
    "                                  self.ps['probability'])\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneSVC):\n",
    "            baby = geneSVC()\n",
    "            ps = self.ps\n",
    "            if rnd.uniform(0,1)<0.5: ps['C'] = rnd.choice([self.ps['C'], other.ps['C']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['kernel'] = rnd.choice([self.ps['kernel'], other.ps['kernel']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['probability'] = rnd.choice([self.ps['probability'], other.ps['probability']])\n",
    "            baby.clf = SVC(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneSVC()\n",
    "        ps = self.ps\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['C'] = rnd.choice([0.1, 1.0, 10.0])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['kernel'] = rnd.choice(['linear', 'rbf'])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['probability'] = rnd.choice([True, False])\n",
    "    \n",
    "        baby.clf = SVC(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneSVC):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        if self.ps['probability']:\n",
    "            return self.clf.predict_proba(x)\n",
    "        else:\n",
    "            return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneLinearSVC(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['C'] = rnd.choice([0.5, 0.75, 0.95, 1.0])\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = LinearSVC(**ps, max_iter=10000)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"LinearSVC(%s)\" % (self.ps['C'])\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneLinearSVC):\n",
    "            baby = geneLinearSVC()\n",
    "            ps = self.ps\n",
    "            if rnd.uniform(0,1)<0.5: ps['C'] = rnd.choice([self.ps['C'], other.ps['C']])\n",
    "            baby.clf = LinearSVC(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneLinearSVC()\n",
    "        ps = self.ps\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['C'] = rnd.choice([0.5, 0.75, 0.95, 1.0])\n",
    "        baby.clf = LinearSVC(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneLinearSVC):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneKNeighborsClassifier(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['weights'] = rnd.choice(['uniform', 'distance'])\n",
    "        ps['algorithm'] = rnd.choice(['auto', 'ball_tree', 'kd_tree', 'brute'])\n",
    "        ps['n_neighbors'] = rnd.choice([2, 4, 8, 15, 25])\n",
    "        ps['leaf_size'] = rnd.choice([10, 25, 50, 75])\n",
    "        ps['p'] = rnd.choice([2, 3])\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = KNeighborsClassifier(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        s = \"\"\n",
    "        for k,v in self.ps.items():\n",
    "            s += '%s: %s\\n' % (k,v)\n",
    "        return \"KNC(%s)\" % (s)\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneKNeighborsClassifier):\n",
    "            baby = geneKNeighborsClassifier()\n",
    "            ps = self.ps\n",
    "            if rnd.uniform(0,1)<0.5: ps['weights'] = rnd.choice([self.ps['weights'], other.ps['weights']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['algorithm'] = rnd.choice([self.ps['algorithm'], other.ps['algorithm']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['n_neighbors'] = rnd.choice([self.ps['n_neighbors'], other.ps['n_neighbors']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['leaf_size'] = rnd.choice([self.ps['leaf_size'], other.ps['leaf_size']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['p'] = rnd.choice([self.ps['p'], other.ps['p']])\n",
    "            baby.clf = KNeighborsClassifier(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneKNeighborsClassifier()\n",
    "        ps = self.ps\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['weights'] = rnd.choice(['uniform', 'distance'])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['algorithm'] = rnd.choice(['auto', 'ball_tree', 'kd_tree', 'brute'])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['n_neighbors'] = rnd.choice([2, 4, 8, 15, 25])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['leaf_size'] = rnd.choice([10, 25, 50, 75])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['p'] = rnd.choice([2, 3])\n",
    "        baby.clf = KNeighborsClassifier(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneKNeighborsClassifier):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BaggingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneBaggingClassifier(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['n_estimators'] = rnd.choice([10, 50, 100, 200])\n",
    "        ps['max_samples'] = rnd.choice([0.1, 0.33, 0.75, 1.0])\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = BaggingClassifier(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"BaggingClf(%s, %s)\" % (self.ps['n_estimators'], self.ps['max_samples'])\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneBaggingClassifier):\n",
    "            baby = geneBaggingClassifier()\n",
    "            ps = self.ps\n",
    "            if rnd.uniform(0,1)<0.5: ps['n_estimators'] = rnd.choice([self.ps['n_estimators'], other.ps['n_estimators']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['max_samples'] = rnd.choice([self.ps['max_samples'], other.ps['max_samples']])\n",
    "            \n",
    "            baby.clf = BaggingClassifier(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneBaggingClassifier()\n",
    "        ps = self.ps\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['n_estimators'] = rnd.choice([10, 50, 100, 200])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['max_samples'] = rnd.choice([0.1, 0.33, 0.75, 1.0])\n",
    "        \n",
    "        baby.clf = BaggingClassifier(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneBaggingClassifier):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneGradientBoostingClassifier(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['loss'] = rnd.choice(['deviance', 'exponential'])\n",
    "        ps['max_depth'] = rnd.choice([1, 5, 10, 15])\n",
    "        ps['max_features'] = rnd.choice(['sqrt', 'log2', None])\n",
    "        ps['learning_rate'] = rnd.choice([0.001, 0.05, 0.2])\n",
    "        ps['subsample'] = rnd.choice([0.5, 0.8, 0.95, 1.0])\n",
    "        ps['n_estimators'] = rnd.choice([10, 100, 200, 300, 500])\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = GradientBoostingClassifier(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"GBC(%s)\" % (self.ps['n_estimators'])\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneGradientBoostingClassifier):\n",
    "            baby = geneGradientBoostingClassifier()\n",
    "            ps = self.ps\n",
    "\n",
    "            if rnd.uniform(0,1)<0.5: ps['loss'] = rnd.choice([self.ps['loss'], other.ps['loss']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['max_depth'] = rnd.choice([self.ps['max_depth'], other.ps['max_depth']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['max_features'] = rnd.choice([self.ps['max_features'], other.ps['max_features']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['learning_rate'] = rnd.choice([self.ps['learning_rate'], other.ps['learning_rate']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['subsample'] = rnd.choice([self.ps['subsample'], other.ps['subsample']])\n",
    "            if rnd.uniform(0,1)<0.5: ps['n_estimators'] = rnd.choice([self.ps['n_estimators'], other.ps['n_estimators']])\n",
    "            \n",
    "            baby.clf = GradientBoostingClassifier(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneGradientBoostingClassifier()\n",
    "        ps = self.ps\n",
    "        \n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['loss'] = rnd.choice(['deviance', 'exponential'])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['max_depth'] = rnd.choice([1, 5, 10, 15])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['max_features'] = rnd.choice(['sqrt', 'log2', None])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['learning_rate'] = rnd.choice([0.001, 0.05, 0.2])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['subsample'] = rnd.choice([0.5, 0.8, 0.95, 1.0])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['n_estimators'] = rnd.choice([10, 100, 200, 300, 500])       \n",
    "        \n",
    "        baby.clf = GradientBoostingClassifier(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneGradientBoostingClassifier):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ExtraTreesClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "class geneExtraTreesClassifier(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['n_estimators'] = rnd.choice([10, 25, 50, 75])\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = ExtraTreesClassifier(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"ETC(%s)\" % (self.ps['n_estimators'])\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneExtraTreesClassifier):\n",
    "            baby = geneExtraTreesClassifier()\n",
    "            ps = self.ps\n",
    "\n",
    "            if rnd.uniform(0,1)<0.5: ps['n_estimators'] = rnd.choice([self.ps['n_estimators'], other.ps['n_estimators']])\n",
    "            \n",
    "            baby.clf = ExtraTreesClassifier(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneExtraTreesClassifier()\n",
    "        ps = self.ps\n",
    "        \n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['n_estimators'] = rnd.choice([10, 25, 50, 75])       \n",
    "        \n",
    "        baby.clf = ExtraTreesClassifier(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneExtraTreesClassifier):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LightGBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneLightGBM(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['n_estimators'] = rnd.choice([5, 20, 35, 50, 75, 100, 150, 200, 350, 500, 750, 1000])\n",
    "        ps['boosting_type'] = rnd.choice(['gbdt', 'dart'])\n",
    "        ps['min_child_samples'] = rnd.choice([1, 5, 7, 10, 15, 20, 35, 50, 100, 200, 500, 1000])\n",
    "        ps['num_leaves'] = rnd.choice([2, 4, 7, 10, 15, 20, 25, 30, 35, 40, 50, 65, 80, 100, 125, 150, 200, 250])\n",
    "        ps['colsample_bytree'] = rnd.choice([0.7, 0.9, 1.0])\n",
    "        ps['subsample'] = rnd.choice([0.7, 0.9, 1.0])\n",
    "        ps['learning_rate'] = rnd.choice([0.01, 0.05, 0.1])\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = LightGBMWrapper(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"LightGBM()\"\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneLightGBM):\n",
    "            baby = geneLightGBM()\n",
    "            ps = self.ps\n",
    "            \n",
    "            for k, v in ps.items():\n",
    "                if rnd.uniform(0,1)<0.5: ps[k] = rnd.choice([self.ps[k], other.ps[k]])\n",
    "            \n",
    "            baby.clf = LightGBMWrapper(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneLightGBM()\n",
    "        ps = self.ps\n",
    "        \n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['n_estimators'] = rnd.choice([5, 20, 35, 50, 75, 100, 150, 200, 350, 500, 750, 1000])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['boosting_type'] = rnd.choice(['gbdt', 'dart'])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['min_child_samples'] = rnd.choice([1, 5, 7, 10, 15, 20, 35, 50, 100, 200, 500, 1000])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['num_leaves'] = rnd.choice([2, 4, 7, 10, 15, 20, 25, 30, 35, 40, 50, 65, 80, 100, 125, 150, 200, 250])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['colsample_bytree'] = rnd.choice([0.7, 0.9, 1.0])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['subsample'] = rnd.choice([0.7, 0.9, 1.0])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['learning_rate'] = rnd.choice([0.01, 0.05, 0.1])\n",
    "        \n",
    "        baby.clf = LightGBMWrapper(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneLightGBM):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneCatBoostClassifier(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['depth'] = rnd.choice([1, 3, 5, 7, 9, 12, 15, 20, 32])\n",
    "        ps['l2_leaf_reg'] = rnd.choice([.0000001, .000001, .00001, .0001, .001, .01, .1])\n",
    "        ps['learning_rate'] = rnd.choice([0.01, 0.05, 0.1, 0.15, 0.2, 0.3])\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = CatBoostClassifier(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"CBC()\"\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneCatBoostClassifier):\n",
    "            baby = geneCatBoostClassifier()\n",
    "            ps = self.ps\n",
    "            \n",
    "            for k, v in ps.items():\n",
    "                if rnd.uniform(0,1)<0.5: ps[k] = rnd.choice([self.ps[k], other.ps[k]])\n",
    "            \n",
    "            baby.clf = CatBoostClassifier(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneCatBoostClassifier()\n",
    "        ps = self.ps\n",
    "        \n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['depth'] = rnd.choice([1, 3, 5, 7, 9, 12, 15, 20, 32])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['l2_leaf_reg'] = rnd.choice([.0000001, .000001, .00001, .0001, .001, .01, .1])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['learning_rate'] = rnd.choice([0.01, 0.05, 0.1, 0.15, 0.2, 0.3])\n",
    "        \n",
    "        baby.clf = CatBoostClassifier(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneCatBoostClassifier):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "class geneXGBClassifier(BaseObject): \n",
    "    def __init__(self):\n",
    "        ps = {}\n",
    "        ps['max_depth'] = rnd.choice([1, 3, 5, 7, 10, 15])\n",
    "        ps['learning_rate'] = rnd.choice([0.01, 0.05, 0.1, 0.2])\n",
    "        ps['n_estimators'] = rnd.choice([50, 100, 200,])\n",
    "        ps['min_child_weight'] = rnd.choice([1, 5, 10, 50])\n",
    "        ps['subsample'] = rnd.choice([0.5, 0.8, 1.0])\n",
    "        ps['colsample_bytree'] = rnd.choice([0.5, 0.8, 1.0])\n",
    "        \n",
    "        self.ps = ps\n",
    "        self.clf = XGBClassifier(**ps)\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return \"XGB()\"\n",
    "    \n",
    "    def mate(self, other):\n",
    "        if isinstance(other, geneXGBClassifier):\n",
    "            baby = geneXGBClassifier()\n",
    "            ps = self.ps\n",
    "            \n",
    "            for k, v in ps.items():\n",
    "                if rnd.uniform(0,1)<0.5: ps[k] = rnd.choice([self.ps[k], other.ps[k]])\n",
    "            \n",
    "            baby.clf = XGBClassifier(**ps)\n",
    "            return baby\n",
    "        else:\n",
    "            return rnd.choice([self, other])\n",
    "    \n",
    "    def mutate(self):\n",
    "        baby = geneXGBClassifier()\n",
    "        ps = self.ps\n",
    "            \n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['max_depth'] = rnd.choice([1, 3, 5, 7, 10, 15])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['learning_rate'] = rnd.choice([0.01, 0.05, 0.1, 0.2])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['n_estimators'] = rnd.choice([50, 100, 200,])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['min_child_weight'] = rnd.choice([1, 5, 10, 50])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['subsample'] = rnd.choice([0.5, 0.8, 1.0])\n",
    "        if rnd.uniform(0,1)<mutation_prob: ps['colsample_bytree'] = rnd.choice([0.5, 0.8, 1.0])\n",
    "        \n",
    "        baby.clf = XGBClassifier(**ps)\n",
    "        \n",
    "        if rnd.uniform(0,1)<replace_class_prob: \n",
    "            return rnd.choice(derived_list)()\n",
    "        \n",
    "        return baby\n",
    "    \n",
    "    def distance_to(self, other):\n",
    "        if isinstance(other, geneXGBClassifier):\n",
    "            return 0.0\n",
    "        else:\n",
    "            return class_distance\n",
    "    \n",
    "    def fit(self, x, y):\n",
    "        self.clf.fit(x, y)\n",
    "        \n",
    "    def transform(self, x, y):\n",
    "        return self.clf.predict(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The GA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": [],
    "run_control": {
     "marked": false
    }
   },
   "source": [
    "#### NEAT Parameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# ... \n",
    "params = NEAT.Parameters()\n",
    "\n",
    "params.PopulationSize = 120\n",
    "params.DynamicCompatibility = True\n",
    "params.YoungAgeTreshold = 3\n",
    "params.SpeciesMaxStagnation = 10000\n",
    "params.OldAgeTreshold = 1000\n",
    "params.MinSpecies = 2\n",
    "params.MaxSpecies = 6\n",
    "params.RouletteWheelSelection = False\n",
    "params.ArchiveEnforcement = True\n",
    "params.InnovationsForever = True\n",
    "\n",
    "params.ConstraintTrials = 12800000\n",
    "\n",
    "params.MutateAddNeuronProb = 0.01\n",
    "params.MutateAddLinkProb = 0.03\n",
    "#params.MutateRemLinkProb = 0.1/4\n",
    "params.RecurrentProb = 0.0\n",
    "params.MaxWeight = 3.0\n",
    "params.MinWeight = -3.0\n",
    "\n",
    "params.MutateWeightsProb = 0.25\n",
    "params.MutateActivationAProb = 0.0\n",
    "params.MutateActivationBProb = 0.0\n",
    "params.MutateNeuronTimeConstantsProb = 0.0\n",
    "params.MutateNeuronBiasesProb = 0.0\n",
    "\n",
    "params.MutateGenomeTraitsProb = 0.0\n",
    "params.MutateNeuronTraitsProb = 0.5\n",
    "params.MutateLinkTraitsProb = 0.0\n",
    "\n",
    "params.OverallMutationRate = 0.7\n",
    "params.CrossoverRate = 0.7\n",
    "params.MultipointCrossoverRate = 0.4\n",
    "params.SurvivalRate = 0.2\n",
    "params.InterspeciesCrossoverRate = 0.005\n",
    "params.PreferFitterParentRate = 0.5\n",
    "\n",
    "params.DontUseBiasNeuron = True\n",
    "params.AllowLoops = False\n",
    "params.AllowClones = True\n",
    "\n",
    "params.ExcessCoeff = 1.0\n",
    "params.DisjointCoeff = 1.0\n",
    "\n",
    "params.WeightDiffCoeff = 0.1\n",
    "params.TimeConstantDiffCoeff = 0.0\n",
    "params.BiasDiffCoeff = 0.0\n",
    "params.ActivationADiffCoeff = 0.0\n",
    "params.ActivationBDiffCoeff = 0.0\n",
    "params.NormalizeGenomeSize = True\n",
    "\n",
    "params.MinCompatTreshold = 0.0\n",
    "params.CompatTreshold = 1.25\n",
    "params.CompatTreshChangeInterval_Evaluations = 1\n",
    "params.CompatTresholdModifier = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "derived_list = [\n",
    "                genePCA, \n",
    "                #geneLDA,\n",
    "                #geneQDA,\n",
    "                geneSelectKBest, \n",
    "                geneSelectPercentile,\n",
    "                geneSelectFpr,\n",
    "                geneSelectFdr,\n",
    "                geneSelectFwe,\n",
    "                geneVarianceThreshold,\n",
    "                geneLinear, \n",
    "                geneSelectSlice,\n",
    "                geneNormalize, \n",
    "                #geneDictionaryLearning,\n",
    "                geneFastICA, \n",
    "    \n",
    "                geneLogisticRegression, \n",
    "                #geneDecisionTreeClassifier,\n",
    "                #geneSVC, \n",
    "                #geneLinearSVC,\n",
    "                geneKNeighborsClassifier,\n",
    "                #geneBaggingClassifier,\n",
    "                #geneGradientBoostingClassifier,\n",
    "                #geneExtraTreesClassifier,\n",
    "                #geneLightGBM,\n",
    "                #geneCatBoostClassifier, \n",
    "                #geneXGBClassifier,\n",
    "               ]\n",
    "probs = [1.0]*len(derived_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Genome constraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def fails_constraints(genome):\n",
    "    \n",
    "    try:\n",
    "        ts = genome.GetNeuronTraits()\n",
    "        o = None\n",
    "        for t in ts:\n",
    "            if t[1]=='output': \n",
    "                o = t[2]\n",
    "            else:\n",
    "                if t[1]=='hidden':\n",
    "                    if not (isinstance(t[2]['node'], genePCA) or \n",
    "                        isinstance(t[2]['node'], geneSelectKBest) or \n",
    "                        isinstance(t[2]['node'], geneSelectPercentile) or                         \n",
    "                        isinstance(t[2]['node'], geneVarianceThreshold) or                       \n",
    "                        #isinstance(t[2]['node'], geneLinear) or           \n",
    "                        isinstance(t[2]['node'], geneNormalize) or                    \n",
    "                        isinstance(t[2]['node'], geneSelectSlice)                         \n",
    "                       ):\n",
    "                        return True\n",
    "                \n",
    "        if not (isinstance(o['node'], geneLogisticRegression) #or \n",
    "              #  isinstance(o['node'], geneSVC) or\n",
    "              #  isinstance(o['node'], geneDecisionTreeClassifier) or\n",
    "              #  isinstance(o['node'], geneKNeighborsClassifier)  or \n",
    "              #  isinstance(o['node'], geneBaggingClassifier) or\n",
    "              #  isinstance(o['node'], geneGradientBoostingClassifier) or\n",
    "              #  isinstance(o['node'], geneExtraTreesClassifier) or\n",
    "              #  isinstance(o['node'], geneLightGBM) or\n",
    "              #  isinstance(o['node'], geneCatBoostClassifier) or\n",
    "              #  isinstance(o['node'], geneXGBClassifier) \n",
    "               ):\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "            \n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "        return True\n",
    "    \n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "params.CustomConstraints = fails_constraints"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "code_folding": []
   },
   "source": [
    "#### Traits setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# merge mode\n",
    "s = ['concat',\n",
    "    # when dimensions match, these can be done, otherwise it defaults to concat\n",
    "     'add','mul','avg','min','max',\n",
    "    ]\n",
    "p = [1.0] * len(s)\n",
    "mm = {'details': {'set': s, 'probs': p},\n",
    "      'importance_coeff': 0.0,\n",
    "      'mutation_prob': 0.3,\n",
    "      'type': 'str'}\n",
    "\n",
    "params.SetNeuronTraitParameters('mm', mm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "node = {'details': (derived_list, probs),\n",
    "          'importance_coeff': 0.1,\n",
    "          'mutation_prob': 0.2,\n",
    "          'type': 'pyclassset'}\n",
    "\n",
    "params.SetNeuronTraitParameters('node', node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "num_inputs = 1\n",
    "num_outputs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "num_input_dims = dx.shape[1]\n",
    "num_output_dims = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "dx.shape, dy.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#dx[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#dy[0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activate graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "def activate_graph(gr, inputs, targets, num_outputs=1, fit=True):\n",
    "    allnodes = list(nx.dfs_postorder_nodes(gr))[::-1]\n",
    "    for a in allnodes: gr._node[a]['act'] = None\n",
    "    \n",
    "    # separate input from non-input nodes\n",
    "    allnodes = [x for x in allnodes if x > num_inputs]\n",
    "    \n",
    "    # input the data\n",
    "    for i,inp in zip(range(1, num_inputs+1), inputs): \n",
    "        gr._node[i]['act'] = np.array(inp).reshape(inp.shape[0], -1)\n",
    "        \n",
    "    # pass through the graph\n",
    "    for an in allnodes:\n",
    "        #print(gr.node[a], end=' ')\n",
    "        mm = gr._node[an]['mm']\n",
    "        \n",
    "        # collect the inputs to this node\n",
    "        \n",
    "        # also sort the incoming edges by id for consistency\n",
    "        inedg = list(gr.in_edges(an))\n",
    "        inps = [gr._node[i]['act'] for i,o in inedg]\n",
    "        \n",
    "        if use_weights:\n",
    "            inedgw = list(gr.in_edges(an, data=1))\n",
    "            ws = [ts['w'] for i,o,ts in inedgw]\n",
    "            # weighted stack\n",
    "            inps = [w*x for w,x in zip(ws, inps)]\n",
    "        #else:\n",
    "        #    # not weighted stack\n",
    "        #    inps = np.vstack(inps)\n",
    "        \n",
    "        if (mm == 'concat') or (len(inps)==1) or (not all([x.shape[1] == inps[0].shape[1] for x in inps])):  \n",
    "            if len(inps)>1:\n",
    "                iii = np.concatenate(inps, axis=1)\n",
    "            else:\n",
    "                if isinstance(inps, list):\n",
    "                    iii = inps[0]\n",
    "                else:\n",
    "                    iii = inps\n",
    "        else:\n",
    "            iii = np.array(inps)\n",
    "            if mm == 'add':\n",
    "                iii = np.sum(inps, axis=0)\n",
    "            elif mm == 'mul':\n",
    "                iii = np.prod(inps, axis=0)\n",
    "            elif mm == 'avg':\n",
    "                iii = np.mean(inps, axis=0)\n",
    "            elif mm == 'min':\n",
    "                iii = np.min(inps, axis=0)\n",
    "            elif mm == 'max':\n",
    "                iii = np.max(inps, axis=0)\n",
    "            else:\n",
    "                iii = np.array(iii)\n",
    "        \n",
    "        if fit: \n",
    "            gr._node[an]['node'].fit(iii, targets)\n",
    "        act = gr._node[an]['node'].transform(iii, targets).reshape(iii.shape[0], -1)\n",
    "        \n",
    "        # store activation\n",
    "        gr._node[an]['act'] = act\n",
    "\n",
    "    outputs = [gr._node[o]['act'] for o in allnodes[-num_outputs:]]\n",
    "    outputs = np.array(outputs[0])\n",
    "    return np.array(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "is_executing": false
    },
    "run_control": {
     "marked": false
    }
   },
   "outputs": [],
   "source": [
    "# evaluation function \n",
    "pred_mode = 'c'\n",
    "\n",
    "def fitter(gr, a, b, fit):\n",
    "    return activate_graph(gr, [a], b, fit=fit)\n",
    "\n",
    "def evaluate(args):\n",
    "    idx, gr, dx, dy, ltr, ntr, precomp = args\n",
    "    ntr = [x for x in ntr if x[1]!='input']\n",
    "    \n",
    "    alls = [w for i,o,tr,w in ltr]\n",
    "    ws = alls[0:len(ltr)]\n",
    "    for (i,o,tr,w),nw in zip(ltr, ws):\n",
    "        gr.adj[i][o]['w'] = nw\n",
    "    \n",
    "    if pred_mode=='r':\n",
    "        pdy = np.digitize(dy.reshape(-1), bins=np.linspace(np.min(dy), np.max(dy),10))\n",
    "    else:\n",
    "        pdy = dy.reshape(-1)\n",
    "    \n",
    "    try:\n",
    "        acc = 0 \n",
    "        \n",
    "        for trial in range(num_trials):\n",
    "\n",
    "            skf = StratifiedKFold(n_splits=CV_splits, shuffle=True, \n",
    "                                  #random_state = rnd.randint(0, 100000)\n",
    "                                 )\n",
    "            cvavg_tr = 0\n",
    "            cvavg_ts = 0\n",
    "            for tr, ts in (skf.split(dx, pdy)):\n",
    "                x_train = dx[tr]\n",
    "                y_train = dy[tr]\n",
    "                x_test = dx[ts]\n",
    "                y_test = dy[ts]\n",
    "                \n",
    "                a_tr = fitter(gr, x_train, y_train.reshape(-1), True)#activate_graph(gr, [x_train], y_train, fit=True)\n",
    "                a_ts = fitter(gr, x_test, y_test.reshape(-1), False)#activate_graph(gr, [x_test], y_test, fit=False)\n",
    "                #print(a_tr, a_ts)\n",
    "                \n",
    "                def fixx(x):\n",
    "                    x = x.reshape(x.shape[0], -1)\n",
    "                    if x.shape[1] > 1: \n",
    "                        x = np.mean(x, axis=1)\n",
    "                    #x = np.round(x)\n",
    "                    return x.reshape(x.shape[0],-1)\n",
    "\n",
    "                a = fixx(a_tr)\n",
    "                b = fixx(a_ts)\n",
    "                \n",
    "                #print(a.reshape(-1), len(a.reshape(-1)), np.sum(a.reshape(-1) == y_train.reshape(-1)),\n",
    "                #      np.sum(a.reshape(-1) == y_train.reshape(-1)) / len(a.reshape(-1)))\n",
    "                #print(b.reshape(-1), np.sum(b.reshape(-1) == y_test.reshape(-1)), len(b.reshape(-1)), \n",
    "                #      np.sum(b.reshape(-1) == y_test.reshape(-1)) / len(b.reshape(-1)))\n",
    "                #print()\n",
    "\n",
    "                acc_tr = np.sum(a.reshape(-1) == y_train.reshape(-1)) / len(a.reshape(-1))\n",
    "                acc_ts = np.sum(b.reshape(-1) == y_test.reshape(-1)) / len(b.reshape(-1))\n",
    "                cvavg_tr += acc_tr\n",
    "                cvavg_ts += acc_ts\n",
    "\n",
    "            acc += float(cvavg_ts / CV_splits)\n",
    "        \n",
    "        acc /= num_trials\n",
    "        \n",
    "    except Exception as ex:\n",
    "        \n",
    "        #print(ex)\n",
    "        acc = 0.0\n",
    "    \n",
    "    f = acc\n",
    "    \n",
    "    return idx, f, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def decide(x):\n",
    "    return x "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cluster init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### IPs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# if socket.gethostname() == 'laptop':\n",
    "#     cluster='192.168.1.148:8786'\n",
    "# elif socket.gethostname() == 'desktop':\n",
    "#     cluster='192.168.1.148:8786'\n",
    "# else:\n",
    "#     cluster='172.31.43.76:8786'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Scatter objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "# import time\n",
    "# st = time.time()\n",
    "# print('Connecting..')\n",
    "# if cluster:\n",
    "#     client = Client(cluster)\n",
    "# else:\n",
    "#     client = Client()\n",
    "# client.restart(timeout=600)\n",
    "# # push the data to the cluster\n",
    "# print('Scattering data to cluster..')\n",
    "# debugxy=0\n",
    "# if not debugxy:\n",
    "#     fx = client.scatter(dx, broadcast=True, direct=True)\n",
    "#     fy = client.scatter(dy, broadcast=True, direct=True)\n",
    "# else:\n",
    "#     fx, fy = None, None\n",
    "# print(f'done in {time.time()-st} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "#evaluate((0, NEAT.Genome2NX(pop.Species[0].Individuals[2]), dx, dy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "num_trials = 10\n",
    "CV_splits = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "use_weights = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "parallel = 0\n",
    "precomp = None\n",
    "verbose=1\n",
    "use_local_search=0\n",
    "display_whole_pop = 0\n",
    "display_max_species = 8\n",
    "initeval = 1\n",
    "evaluations = 100000\n",
    "display_pop_each = 80000\n",
    "once = False\n",
    "x_shape, ys = dx.shape[1], 1\n",
    "population = params.PopulationSize\n",
    "\n",
    "penalize_stangation = 1\n",
    "penalize_stagnation_evals = 2400\n",
    "\n",
    "max_stagnation = 5000\n",
    "\n",
    "max_nodeslinks_to_output = 4\n",
    "\n",
    "evhist = []\n",
    "best_ever = 0\n",
    "best_gs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Utility stuff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def poplen(pop):\n",
    "    return sum([len(x.Individuals) for x in pop.Species])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def prettydict(d, nonl=False):\n",
    "    i,t,di = d\n",
    "    if not nonl:\n",
    "        ks = '%d - %s: ' % (i, t)\n",
    "    else:\n",
    "        return '%d - %s' % (i, t)\n",
    "    s = []\n",
    "    for k,v in sorted(list(di.items())):\n",
    "        if isinstance(v, float):\n",
    "            s.append( '%s %3.3f' % (k[0:1], v) )\n",
    "        else:\n",
    "            s.append( '%s %s' % (k[0:1], v) )\n",
    "    return ks + ', '.join(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def species_display(pop):\n",
    "    genomes = [x.GetLeader() for x in pop.Species][0:display_max_species]\n",
    "    f, axes = plt.subplots(1, len(genomes), figsize=(len(genomes) * 4.5, 14))\n",
    "    print('Species Representatives:')\n",
    "    if len(genomes)>1:\n",
    "        for i,(ax, g) in enumerate(zip(axes, genomes)):\n",
    "            try:\n",
    "                img = NEAT.viz.Draw(g, size=(300, 400))[:, 0:230]\n",
    "                ax.imshow(img)\n",
    "                ax.set_title('%3.6f | %3.2f%%' % (decide(g.GetFitness()),\n",
    "                                                  (len(pop.Species[i].Individuals)/poplen(pop))*100 ))\n",
    "                s = '\\n'.join([prettydict(x) for x in g.GetNeuronTraits() if x[1] != 'input'][0:8])\n",
    "                s += '\\n=============\\n'\n",
    "                s += '\\n'.join([prettydict(x, nonl=True) for x in g.GetLinkTraits(False)][0:8])\n",
    "                ax.set_xlabel(s)\n",
    "            except Exception as ex:\n",
    "                print(ex)\n",
    "    else:\n",
    "        try:\n",
    "            g = pop.GetBestGenome()\n",
    "            img = NEAT.viz.Draw(g, size=(300, 400))[:, 0:230]\n",
    "            axes.imshow(img)\n",
    "            axes.set_title('%3.6f' % (decide(g.GetFitness())))\n",
    "            s = '\\n'.join([prettydict(x) for x in g.GetNeuronTraits() if x[1] != 'input'][0:8])\n",
    "            s += '\\n=============\\n'\n",
    "            s += '\\n'.join([prettydict(x, nonl=True) for x in g.GetLinkTraits(False)][0:8])\n",
    "            axes.set_xlabel(s)\n",
    "        except Exception as ex:\n",
    "            print(ex)\n",
    "    f.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Main loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "nfl = 1\n",
    "# noinspection JupyterKernel\n",
    "# g = NEAT.Genome(0, num_inputs, 1, num_outputs, 0, NEAT.ActivationFunction.RELU,\n",
    "#                     NEAT.ActivationFunction.RELU, 0, params, 1, nfl)\n",
    "\n",
    "gi = NEAT.GenomeInitStruct()\n",
    "gi.NumInputs = num_inputs\n",
    "gi.NumOutputs = num_outputs\n",
    "g = NEAT.Genome(params, gi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pop = NEAT.Population(g, params, True, 1.0, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "pop.RNG.Seed(int(time.clock()*100))\n",
    "#pop.Parameters.AllowClones = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     5,
     13
    ],
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "evhist = []\n",
    "best_gs = []\n",
    "once = False\n",
    "best_ever = 0\n",
    "\n",
    "# rtNEAT code\n",
    "try: \n",
    "    \n",
    "    if initeval: \n",
    "        if verbose:\n",
    "            print('============================================================')\n",
    "            print(\"Please wait for the initial evaluation to complete.\")\n",
    "        now = time.time()\n",
    "        genome_list = []\n",
    "        for s in pop.Species:\n",
    "            for i in s.Individuals:\n",
    "                genome_list.append(i)\n",
    "        sys.stdout.flush()\n",
    "        # turn them into NX networks\n",
    "        grlist = [NEAT.Genome2NX(x, with_weights=1) for x in genome_list]\n",
    "        ltrlist = [x.GetLinkTraits(1) for x in genome_list]\n",
    "        ntrlist = [x.GetNeuronTraits() for x in genome_list]\n",
    "        idlist = [x.GetID() for x in genome_list]\n",
    "        if parallel:\n",
    "            args = list(zip(idlist,\n",
    "                            grlist,\n",
    "                            [fx]*len(grlist),\n",
    "                            [fy]*len(grlist),\n",
    "                            ltrlist,\n",
    "                            ntrlist, \n",
    "                            [precomp]*len(grlist)\n",
    "                            ))\n",
    "        else:\n",
    "            args = list(zip(idlist,\n",
    "                            grlist,\n",
    "                            [dx]*len(grlist),\n",
    "                            [dy]*len(grlist),\n",
    "                            ltrlist,\n",
    "                            ntrlist,\n",
    "                            [precomp]*len(grlist)\n",
    "                            ))\n",
    "\n",
    "        # evaluate all individuals\n",
    "        fitnesses = [0] * len(grlist)\n",
    "        if verbose:\n",
    "            bar = ProgressBar(initial_value=0, max_value=len(grlist))\n",
    "        fff = {}\n",
    "        rss = {}\n",
    "        if parallel:\n",
    "            cp = [client.submit(evaluate, x) for x in args]\n",
    "            for i,ftr in enumerate(as_completed(cp)):\n",
    "                idx, fitness, rsx  = ftr.result()\n",
    "                fff[idx] = fitness\n",
    "                rss[idx] = rsx\n",
    "                if verbose:\n",
    "                    bar.update(i)\n",
    "        else:\n",
    "            for i in range(len(grlist)):\n",
    "                idx, fitness, rsx = evaluate(args[i])\n",
    "                fff[idx] = fitness\n",
    "                rss[idx] = rsx\n",
    "                if verbose:\n",
    "                    bar.update(i)                \n",
    "        if verbose:\n",
    "            bar.finish()\n",
    "\n",
    "        fitness_list = []\n",
    "        rsx_list = []\n",
    "        for gnm in genome_list:\n",
    "            gnm.SetFitness( fff[gnm.GetID()] )\n",
    "            fitness_list.append( fff[gnm.GetID()] )\n",
    "            rsx_list.append( rss[gnm.GetID()] )\n",
    "            gnm.SetEvaluated()\n",
    "\n",
    "        bidx = argmax(fitness_list)\n",
    "        best = fitness_list[bidx]\n",
    "        #if initeval: evhist.append(decide(best))\n",
    "        if best > best_ever:\n",
    "            if verbose:\n",
    "                print('NEW RECORD!')\n",
    "                print('Evaluations:', 0,\n",
    "                      'Fitness:', decide(best),\n",
    "                      'Species:', len(pop.Species))\n",
    "            best_gs.append([NEAT.Genome2NX(genome_list[bidx], with_weights=1), \n",
    "                            genome_list[bidx].GetLinkTraits(1),\n",
    "                            genome_list[bidx].GetNeuronTraits(),\n",
    "                            rsx_list[bidx]\n",
    "                           ])\n",
    "            best_bs = best_gs[-3:]\n",
    "            \n",
    "            if verbose:\n",
    "                mytest = dx_test\n",
    "                _= activate_graph(best_gs[-1][0], [dx], dy, num_outputs=1, fit=True)\n",
    "                p = activate_graph(best_gs[-1][0], [mytest], zeros(dx_test.shape[0]), num_outputs=1, fit=False)\n",
    "                #kg = real_kaggle_score_titanic(np.array(p).reshape(-1), '../../work/automl/titanic/titanic_100p_score.csv')\n",
    "                #print('Real Kaggle score:', kg)\n",
    "                            \n",
    "            if verbose:\n",
    "                print(f'-------- nodes: {genome_list[bidx].NumNeurons()} -------- ')\n",
    "                print('\\n'.join([str(x) for x in genome_list[bidx].GetNeuronTraits() \n",
    "                                 if x[1] != 'input'][0:max_nodeslinks_to_output]))\n",
    "                print(f'-------- links: {genome_list[bidx].NumLinks()} -------- ')\n",
    "                print('\\n'.join([str(x) for x in genome_list[bidx].GetLinkTraits(1)][0:max_nodeslinks_to_output]))\n",
    "                print('----------------------- ')\n",
    "            best_ever = best\n",
    "            if viz and verbose:\n",
    "                species_display(pop)\n",
    "\n",
    "        if verbose:\n",
    "            print(\"Evaluation took\", '%3.2f' % (time.time() - now), \"seconds.\")\n",
    "            \n",
    "    else: \n",
    "        # No initial evaluation, start off with small random fitness\n",
    "        for s in pop.Species:\n",
    "            for i in s.Individuals:\n",
    "                i.SetFitness(rnd.uniform(0,1)/1000)\n",
    "                #i.SetEvaluated()              \n",
    "\n",
    "    if parallel: \n",
    "        genome_list = NEAT.GetGenomeList(pop)\n",
    "        grlist = [NEAT.Genome2NX(x, with_weights=1) for x in genome_list]\n",
    "        ltrlist = [x.GetLinkTraits(1) for x in genome_list]\n",
    "        ntrlist = [x.GetNeuronTraits() for x in genome_list]\n",
    "        idlist = [x.GetID() for x in genome_list]\n",
    "        args = list(zip(idlist,\n",
    "                        grlist,\n",
    "                        [fx]*len(grlist),\n",
    "                        [fy]*len(grlist),\n",
    "                        ltrlist,\n",
    "                        ntrlist,\n",
    "                        [precomp]*len(grlist)\n",
    "                        ))\n",
    "        cp = [client.submit(evaluate, x) for x in args]\n",
    "\n",
    "    if verbose: \n",
    "        print('============================================================')\n",
    "        print('rtNEAT phase')\n",
    "        print('============================================================')\n",
    "\n",
    "        format_custom_text = FormatCustomText('CTresh: %(ctr).6f Species: %(sp)d Last fitness: %(fitness).6f %(vr)s',\n",
    "            dict(\n",
    "                sp=0,\n",
    "                fitness=0.0,\n",
    "                vr=str([]),\n",
    "                ctr=0.0,\n",
    "            ),)\n",
    "\n",
    "        widgets = ['Evaluated: ', Counter('%(value)d'), ' ', format_custom_text,\n",
    "                   ' (', Timer(), ') ', RotatingMarker(), FileTransferSpeed(unit='individuals') ]\n",
    "        bar = ProgressBar(widgets=widgets, initial_value=0, max_value=evaluations)\n",
    "\n",
    "    if parallel: \n",
    "        # parallel continious loop\n",
    "        seq = as_completed(cp)\n",
    "        i=0\n",
    "        olds = []\n",
    "        under_evaluation_now = len(cp)\n",
    "        for f in tqdm(seq):\n",
    "            if i >= evaluations:\n",
    "                [x.cancel() for x in cp]\n",
    "                break\n",
    "            if verbose:\n",
    "                if i > 0: bar.update(i)\n",
    "            i += 1\n",
    "\n",
    "            # get result from evaluation\n",
    "            idx, fitness, rsx = f.result()\n",
    "            if 1:\n",
    "                if idx not in olds:\n",
    "                    # set that individual's fitness\n",
    "                    pop.AccessGenomeByID(idx).SetFitness(fitness)\n",
    "                    pop.AccessGenomeByID(idx).SetEvaluated()\n",
    "                    under_evaluation_now -= 1\n",
    "\n",
    "                    thegenome = pop.AccessGenomeByID(idx)\n",
    "\n",
    "                    #  apply the local search back to genome\n",
    "                    #if use_local_search:\n",
    "                    #    for qx,w in zip(thegenome.LinkGenes,rsx): qx.Weight = w\n",
    "\n",
    "                    # get best fitness in population and print it\n",
    "                    \n",
    "                    if fitness > best_ever:\n",
    "                        if verbose:\n",
    "                            print('NEW RECORD!')\n",
    "                            print('Evaluations:', i,\n",
    "                                  'Fitness:', decide(fitness))\n",
    "                            \n",
    "                        best_gs.append([NEAT.Genome2NX(thegenome, with_weights=1),\n",
    "                                        thegenome.GetLinkTraits(1),\n",
    "                                        thegenome.GetNeuronTraits(),\n",
    "                                        rsx\n",
    "                                       ])\n",
    "                        \n",
    "                        if verbose:\n",
    "                            mytest = dx_test\n",
    "                            _= activate_graph(best_gs[-1][0], [dx], dy, num_outputs=1, fit=True)\n",
    "                            p = activate_graph(best_gs[-1][0], [mytest], zeros(dx_test.shape[0]), num_outputs=1, fit=False)\n",
    "                            #kg = real_kaggle_score_titanic(np.array(p).reshape(-1), '../../work/automl/titanic/titanic_100p_score.csv')\n",
    "                            print('Real Kaggle score:', kg)\n",
    "                            \n",
    "                        evhist.append((decide(fitness)))\n",
    "\n",
    "                        if verbose:\n",
    "                            print(f'-------- nodes: {thegenome.NumNeurons()} -------- ')\n",
    "                            print('\\n'.join([str(x) for x in thegenome.GetNeuronTraits() if x[1] != 'input'][0:max_nodeslinks_to_output]))\n",
    "                            print(f'-------- links: {thegenome.NumLinks()} -------- ')\n",
    "                            print('\\n'.join([str(x) for x in thegenome.GetLinkTraits(1)][0:max_nodeslinks_to_output]))\n",
    "                            print('----------------------- ')\n",
    "                            \n",
    "                        best_ever = fitness\n",
    "                        if viz and verbose:\n",
    "                            species_display(pop)\n",
    "                    elif (i%display_pop_each)==0: \n",
    "                        if viz and verbose:\n",
    "                            species_display(pop)\n",
    "\n",
    "                else:\n",
    "                    if verbose: \n",
    "                        print(f'Fitness of genome #{idx} was not set.')\n",
    "\n",
    "            #except Exception as ex:\n",
    "            #    print(ex)\n",
    "            if verbose:\n",
    "                format_custom_text.update_mapping(fitness=decide(fitness),\n",
    "                                                  sp=len(pop.Species),\n",
    "                                                  ctr=pop.Parameters.CompatTreshold)\n",
    "\n",
    "\n",
    "            # apply exploration pressure to species\n",
    "            if penalize_stangation:\n",
    "                maxfit = max([x.GetFitness() for x in NEAT.GetGenomeList(pop)])\n",
    "                for s in pop.Species:\n",
    "                    if s.EvalsNoImprovement > penalize_stagnation_evals:\n",
    "                        bf = max([x.GetFitness() for x in s.Individuals])\n",
    "                        # make an exception if that species contains the best genome so far\n",
    "                        if bf < maxfit:\n",
    "                            for ind in s.Individuals:\n",
    "                                ind.SetFitness(0.000000001)\n",
    "\n",
    "            if all([x.EvalsNoImprovement > max_stagnation for x in pop.Species]):\n",
    "                break\n",
    "\n",
    "            # create new baby and add to list of tasks\n",
    "            # only add new babies if the population under evaluation is below N%\n",
    "            if under_evaluation_now <= (population*(1/3)):\n",
    "                if not once:\n",
    "                    once=True\n",
    "                    if verbose:\n",
    "                        print(f'rtNEAT reproduction cycle started at evaluation #{i}')\n",
    "\n",
    "                old = NEAT.Genome()\n",
    "                baby = pop.Tick(old)\n",
    "\n",
    "                if old.GetID() != -1:\n",
    "                    olds.append(old.GetID())\n",
    "\n",
    "                newf = client.submit(evaluate, (baby.GetID(),\n",
    "                                                NEAT.Genome2NX(baby, with_weights=1),\n",
    "                                                fx,\n",
    "                                                fy,\n",
    "                                                baby.GetLinkTraits(1),\n",
    "                                                baby.GetNeuronTraits(),\n",
    "                                                precomp\n",
    "                                                ))\n",
    "                seq.add(newf)\n",
    "                under_evaluation_now += 1\n",
    "\n",
    "    else: \n",
    "\n",
    "        # continuous loop\n",
    "        for i in tqdm(range(evaluations)):\n",
    "            if verbose:\n",
    "                bar.update(i)\n",
    "\n",
    "            # get the new baby\n",
    "            old = NEAT.Genome()\n",
    "            baby = pop.Tick(old)\n",
    "\n",
    "            # evaluate it\n",
    "            f = evaluate((baby.GetID(),\n",
    "                          NEAT.Genome2NX(baby, with_weights=1),\n",
    "                          dx,\n",
    "                          dy,\n",
    "                          baby.GetLinkTraits(1),\n",
    "                          baby.GetNeuronTraits(),\n",
    "                          precomp\n",
    "                          ))\n",
    "\n",
    "            fitness = f[1]\n",
    "            rsx = f[2]\n",
    "\n",
    "            baby.SetFitness(fitness)\n",
    "            baby.SetEvaluated()\n",
    "\n",
    "            # get best fitness in population and print it\n",
    "            #evhist.append(decide(fitness))\n",
    "            if fitness > best_ever:\n",
    "                \n",
    "                if verbose:\n",
    "                    print('NEW RECORD!')\n",
    "                    print('Evaluations:', i,\n",
    "                          'Fitness:', decide(fitness))\n",
    "                best_gs.append([NEAT.Genome2NX(baby, with_weights=1),\n",
    "                               baby.GetLinkTraits(1),\n",
    "                               baby.GetNeuronTraits(),\n",
    "                               rsx])\n",
    "                best_bs = best_gs[-3:]\n",
    "                \n",
    "                if verbose:\n",
    "                    mytest = dx_test\n",
    "                    _= activate_graph(best_gs[-1][0], [dx], dy, num_outputs=1, fit=True)\n",
    "                    p = activate_graph(best_gs[-1][0], [mytest], zeros(dx_test.shape[0]), num_outputs=1, fit=False)\n",
    "                    #kg = real_kaggle_score_titanic(np.array(p).reshape(-1), '../../work/automl/titanic/titanic_100p_score.csv')\n",
    "                    #print('Real Kaggle score:', kg)\n",
    "                    \n",
    "                evhist.append((fitness))\n",
    "                \n",
    "                if verbose:                    \n",
    "                    print(f'-------- nodes: {baby.NumNeurons()} -------- ')\n",
    "                    print('\\n'.join([str(x) for x in baby.GetNeuronTraits() if x[1] != 'input'][0:max_nodeslinks_to_output]))\n",
    "                    print(f'-------- links: {baby.NumLinks()} -------- ')\n",
    "                    print('\\n'.join([str(x) for x in baby.GetLinkTraits(1)][0:max_nodeslinks_to_output]))\n",
    "                    print('----------------------- ')\n",
    "                best_ever = fitness\n",
    "                if viz and verbose:\n",
    "                    species_display(pop)\n",
    "            elif (i%display_pop_each)==0: \n",
    "                if viz and verbose:\n",
    "                    species_display(pop)\n",
    "\n",
    "            if all([x.EvalsNoImprovement > max_stagnation for x in pop.Species]):\n",
    "                break\n",
    "\n",
    "            if (i%50000)==0:\n",
    "                _=gc.collect()\n",
    "\n",
    "            #spechist.append([len(pop.Species), pop.Parameters.CompatTreshold])\n",
    "\n",
    "            if verbose:\n",
    "                format_custom_text.update_mapping(fitness=decide(f[1]),\n",
    "                                                  sp=len(pop.Species),\n",
    "                                                  ctr=pop.Parameters.CompatTreshold)\n",
    "\n",
    "except KeyboardInterrupt:\n",
    "    pass\n",
    "\n",
    "except Exception as ex:\n",
    "    print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(array(evhist)[array(evhist)>0.50]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#client.restart(timeout=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_gs[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hs = []\n",
    "# for _ in tqdm(range(10)):\n",
    "#     hs.append( np.sum(activate_graph(best_gs[-1][0], [dx], dy.reshape(-1), num_outputs=1, fit=True).reshape(-1) == dy.reshape(-1)) / dy.shape[0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#_=hist(hs, 20);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try:\n",
    "#     pees = pkl.load(open('predictions.pkl','rb'))\n",
    "# except:\n",
    "#     pees = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # make submission\n",
    "# mytest = dx_test_df.values[:,1:]\n",
    "\n",
    "# len(dx_test_df)\n",
    "\n",
    "# _= activate_graph(best_gs[-1][0], [dx], dy, num_outputs=1, fit=True)\n",
    "# p = activate_graph(best_gs[-1][0], [mytest], zeros(dx_test_df.shape[0]), num_outputs=1, fit=False)\n",
    "\n",
    "# pees.append(p.reshape(-1))\n",
    "# pkl.dump(pees, open('predictions.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testPredictions = array(p).reshape(-1)\n",
    "# pdtest = pd.DataFrame({'PassengerId': dx_test_df.PassengerId.astype(int),\n",
    "#                         'Survived': testPredictions.astype(int)})\n",
    "# pdtest.to_csv('titanic_skneat_1.csv', index=False)# make submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_kaggle_score_titanic(testPredictions, '../../work/automl/titanic/titanic_100p_score.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# make submission\n",
    "submission.time_to_failure = p\n",
    "submission.to_csv('earthquake_deepneat_submission.csv',index=True)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "227.141px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
